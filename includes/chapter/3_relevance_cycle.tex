\chapter{Anforderungsanalyse und Problemdefinition}
Auf Grundlage der in Kapitel 1 dargestellten Problemstellung werden in diesem Kapitel die konkreten Anforderungen an das zu entwickelnde Artefakt systematisch abgeleitet. Als Basis dafür dienen neben einschlägiger Literatur auch Experteninterviews mit einer Motorsport-Ingenieur*in. Dieses Kapitel konkretisiert die Problemstellung zu spezifischen, messbaren Anforderungen und präzisiert die Forschungsfragen, die als Evaluationskriterien für die später entwickelte Lösung dienen. Damit erfüllt dieses Kapitel die systematische \textit{Definition of Objectives} Phase des DSR-Prozesses.

\section{Problemdomäne und Use-Case-Identifikation}

Im Rahmen dieses Projekts wird mit Telemetriedaten von Porsche \ac{LMDh}-Rennwagen 
gearbeitet.  \ac{LMDh} ist eine Fahrzeugklasse für 
Langstreckenrennen, die in den Weltmeisterschaften \ac{IMSA} und \ac{WEC} eingesetzt wird.\footnote{Vgl. 
\cite{Porsche2023LMDh}; vgl. auch \cite{24hLeMans2025Classes}}

Die Telemetriedaten werden über mehrere Tausend Sensoren in den Rennwagen erfasst und liefern 
während Trainings- und Rennsessions ununterbrochen Messwerte, die in Echtzeit 
in die Porsche Motorsport Cloud-Plattform übertragen werden.\footnote{Vgl. 
Experteninterview 2, 12.09.2025, Z. 19-22}
Dort liegen sie als Zeitreihendaten vor und stehen Performance Engineers wahlweise direkt für Detailanalysen zur Verfügung oder werden in Form von Metriken aufbereitet. Unter Metriken versteht man statistische Kennzahlen wie Durchschnitt, Minimum oder Maximum über definierte Zeitabschnitte, zum Beispiel pro Runde oder pro Strecken-Sektion. Diese Metriken bilden die Grundlage, auf der Performance Engineers ihre tägliche Arbeit aufbauen.\footnote{Vgl. Experteninterview 2, 12.09.2025, Z. 19-22}

Im aktuellen Workflow prüfen Performance Engineers zunächst die Kennzahlen in Dashboards, um Auffälligkeiten zu erkennen. Das können Temperatursprünge in schnellen Kurven sein oder ungewöhnlich hoher Reifenverschleiß auf bestimmten Streckenabschnitten.\footnote{Vgl. Experteninterview 1, 29.08.2025, Z. 3-27} Allerdings fällt auf, dass diese Auswertung fast ausschließlich manuell erfolgt. Die Ingenieur*innen verbringen pro Rennwochenende mehrere Stunden damit, Metriken zu sichten, Trends zusammenzuführen und in Setup-Empfehlungen zu übersetzen. Das führt nicht nur zu Verzögerungen, sondern birgt auch das Risiko, subtilere Muster zu übersehen, etwa wenn ein Zusammenspiel aus Streckentemperatur, Gas- und Bremsprofil nur in Extremlagen auffällt.\footnote{Vgl. Experteninterview 1, 29.08.2025, Z. 62-66}

Die Fahrzeugbalance-Vorhersage ermöglicht einen Wechsel von reaktiver zu vorausschauender Optimierung. Ingenieur*innen könnten Anpassungen bereits dann vornehmen, wenn sich ein akuter Über- oder Untersteuern-Trend ankündigt. Darüber hinaus verspricht dieser Use Case eine objektivere Entscheidungsbasis: Anstelle persönlicher Einschätzungen stünden reproduzierbare Kennzahlenmodelle im Mittelpunkt. Damit würde das bestehende System von punktueller Datenansicht auf datengetriebene Automatisierung übergehen und den Zeitaufwand für Analyse sowie Setup-Änderungen deutlich verringern.\footnote{Vgl. Experteninterview 2, 12.09.2025, Z. 29-32}



\section{Anforderungsableitung}

Aus den beiden Experteninterviews mit dem Performance Engineer am 29.08.2025 und 12.09.2025 lassen sich konkrete Anforderungen an das \ac{ML}-Artefakt ableiten.

Die erste und primäre funktionale Anforderung betrifft die Fähigkeit, die Fahrzeugbalance auf Basis vorhandener Telemetrie-Metriken zuverlässig vorherzusagen. Dieses Ziel folgt direkt aus der Erkenntnis, dass manuelle Analysen mehrere Stunden pro Rennwochenende beanspruchen und dass frühe Hinweise auf Balanceabweichungen häufig erst verspätet offensichtlich werden.\footnote{Vgl. Experteninterview 1, 29.08.2025, Z. 62-66} Das Modell soll ohne manuelle Intervention vorhersagen können, welche Fahrzeugbalance-Werte für eine gegebene Kombination von Telemetrie-Inputs zu erwarten sind. Damit wird das Ziel einer automatisierten Fahrzeugbalance-Vorhersage definiert.

Neben der reinen Funktionalität muss das Modell eine hinreichende 
Vorhersagegenauigkeit aufweisen. In der Fahrzeugtechnik und 
Ingenieurwissenschaften wird für Validierungsmodelle ein R²-Wert 
von mindestens 0,7 angestrebt, um praktische Einsatzfähigkeit 
zu gewährleisten.\footnote{Vgl. \cite{ODonnell2024}, S. 1 ff.} 
Unterhalb dieses Schwellenwerts ist die Prognose zu unsicher, 
um darauf Setup-Entscheidungen zu stützen.

Die dritte Anforderung betrifft die Reproduzierbarkeit und Dokumentation. Eine lückenlose Dokumentation aller Eingangsdaten, Vorverarbeitungsschritte, Modellparameter und Evaluationsergebnisse ist vorgesehen. Nur so kann vollständige Reproduzierbarkeit gewährleistet werden, und die erstellten Prognosen bleiben validierbar.\footnote{Vgl. \cite{Venable2016}, S. 79} Diese Anforderung entspricht den Prinzipien der \ac{DSR}-Methodik, die eine nachvollziehbare Artefakt-Entwicklung fordert.

\section{Abgrenzung des Design Science Research Artefakts}

Das entwickelte Artefakt beschränkt sich auf ein Vorhersagemodell für Fahrzeugbalance-Werte, basierend auf aggregierten Telemetrie-Metriken pro Runde. Diese fokussierte Auslegung ermöglicht es, das Projekt im vorgesehenen Zeitrahmen vollständig durchzuführen.

Hinsichtlich der Implementierung arbeitet das Modell auf rundenweise aggregierten Metriken, nicht auf Rohdaten-Sensorströmen. Dies reduziert die Komplexität erheblich und erlaubt fokussiertere Feature-Engineering-Strategien.\footnote{Vgl. Kap. 4.2} Eine Echtzeitvorhersage, die kontinuierlich auf Sensor-Einzelmessungen reagiert, wird damit nicht angestrebt.

Schließlich liefert das Modell keine direkten Setup-Vorschläge, sondern ausschließlich Fahrzeug\-balance-Prognosen. Die Ableitung von Setup-Änderungen aus diesen Prognosen bleibt in der Verantwortung der Performance Engineers und wird nicht automatisiert. Damit bleibt die Entscheidungshoheit bei den Ingenieur*innen, während das Modell als Entscheidungsunterstützungssystem fungiert.

Diese Abgrenzung reduziert den Projektumfang auf ein klar definiertes \ac{ML}-Regressionsproblem und ermöglicht eine fokussierte Evaluation im \ac{DSR}-Kontext.\footnote{Vgl. \cite{Hevner2004}, S. 83}



\section{Forschungsfragen}

Aus der Problemdefinition und den Anforderungen ergeben sich drei zentrale Forschungsfragen, die das Projekt leiten und in den nachfolgenden Kapiteln beantwortet werden.

Die erste Forschungsfrage adressiert die grundlegende Machbarkeit des Ansatzes: Können Gradient Boosting Decision Trees (GBDT) Fahrzeugbalance-Verhalten in Motorsport-Telemetriedaten vorhersagen? GBDT gelten als state-of-the-art für strukturierte Regressionsprobleme,\footnote{Vgl. \cite{Chen2016}, S. 785 ff.} aber ihre Anwendbarkeit auf Motorsport-Telemetriedaten ist bisher nicht systematisch untersucht. Diese Frage wird in Kapitel 5 und 6 umfassend beantwortet.

Die zweite Forschungsfrage vergleicht zwei konkrete Algorithmen: Welcher Algorithmus (XGBoost vs. LightGBM) generalisiert besser auf unbekannte Rennevents?  Welcher Algorithmus robuster generalisiert, ist unklar und wird durch systematischen Vergleich auf Event-basierten Validierungsdatensätzen beantwortet (Kapitel 5.2).

Die dritte Forschungsfrage konzentriert sich auf die Inputseite des Modells: Wie wirken sich Datenvorbereitung (Feature-Engineering, Glättung, Aggregation) und Hyperparameter-Tuning auf die Vorhersagegenauigkeit aus? Verschiedene Vorverarbeitungsschritte, kategoriale Features, Zielvariablen-Glättung und Hyperparameter-Komplexitätsstufen werden getestet, um ihren Einfluss auf Performance zu quantifizieren (Kapitel 4.2, 4.3, 5.2).

Diese drei Forschungsfragen strukturieren den Aufbau der Arbeit: Kapitel 4 entwickelt das Artefakt systematisch, Kapitel 5 evaluiert es anhand der Forschungsfragen, und Kapitel 6 synthetisiert die Erkenntnisse in Design Knowledge für zukünftige Arbeiten.